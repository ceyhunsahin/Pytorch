{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6aabe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9dd5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7833c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2920, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee8a423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3028, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(\n",
    "                     nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8b22d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1800, -1.2938, -0.1568],\n",
      "        [-0.3265,  0.6399,  0.5399],\n",
      "        [ 0.0610,  1.4456, -0.1612]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59d91c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0324, 1.6739, 0.0246],\n",
      "        [0.1066, 0.4095, 0.2915],\n",
      "        [0.0037, 2.0897, 0.0260]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "899d0be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7fbb974fde80>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c81595de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5175, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a31b569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fd8faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0400, -0.2875, -0.0348],\n",
      "        [-0.0725,  0.1422,  0.1200],\n",
      "        [ 0.0135,  0.3212, -0.0358]])\n",
      "tensor([[ 0.0400, -0.2875, -0.0348],\n",
      "        [-0.0725,  0.1422,  0.1200],\n",
      "        [ 0.0135,  0.3212, -0.0358]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(2*x/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e54fcf",
   "metadata": {},
   "source": [
    "# Loss and Autograd together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7096ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17f2cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 7.5960e-04,  0.0000e+00, -1.0865e-03,  ..., -4.3992e-04,\n",
      "          4.1695e-04,  5.6578e-04],\n",
      "        [-1.2480e-03,  0.0000e+00,  1.9976e-04,  ...,  2.0106e-03,\n",
      "          6.2429e-04, -5.7429e-04],\n",
      "        [ 1.0194e-03,  0.0000e+00,  4.4186e-04,  ...,  5.6193e-04,\n",
      "         -4.6074e-05,  8.1523e-05],\n",
      "        ...,\n",
      "        [-1.6554e-03,  0.0000e+00, -1.1541e-03,  ..., -2.8535e-03,\n",
      "         -6.6470e-04,  4.0578e-04],\n",
      "        [-3.0974e-03,  0.0000e+00, -3.9057e-03,  ..., -3.7331e-05,\n",
      "          1.4043e-04, -1.8184e-04],\n",
      "        [ 9.9441e-04,  0.0000e+00, -8.6681e-04,  ...,  2.3199e-04,\n",
      "          3.9418e-04,  6.3042e-04]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[2].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[2].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12991d00",
   "metadata": {},
   "source": [
    "# Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3497a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9fe1",
   "metadata": {},
   "source": [
    "Now we know how to use all the individual parts so it's time to see how they work together. Let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
    "\n",
    "- Make a forward pass through the network\n",
    "- Use the network output to calculate the loss\n",
    "- Perform a backward pass through the network with loss.backward() to calculate the gradients\n",
    "- Take a step with the optimizer to update the weights\n",
    "Below I'll go through one training step and print out the weights and gradients so you can see how it changes. Note that I have a line of code optimizer.zero_grad(). When you do multiple backwards passes with the same parameters, the gradients are accumulated. This means that you need to zero the gradients on each training pass or you'll retain gradients from previous training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ffdfc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0346,  0.0075, -0.0243,  ..., -0.0262,  0.0271,  0.0190],\n",
      "        [ 0.0204, -0.0107,  0.0112,  ..., -0.0150,  0.0293, -0.0259],\n",
      "        [ 0.0314,  0.0012,  0.0093,  ...,  0.0076, -0.0251, -0.0213],\n",
      "        ...,\n",
      "        [ 0.0224,  0.0255, -0.0241,  ..., -0.0061, -0.0236, -0.0284],\n",
      "        [ 0.0113, -0.0223, -0.0012,  ...,  0.0321, -0.0262,  0.0207],\n",
      "        [ 0.0240, -0.0055, -0.0259,  ..., -0.0183, -0.0315, -0.0128]],\n",
      "       requires_grad=True)\n",
      "2.313371419906616\n",
      "Gradient - tensor([[-0.0104, -0.0104, -0.0104,  ..., -0.0104, -0.0104, -0.0104],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0180, -0.0180, -0.0180,  ..., -0.0180, -0.0180, -0.0180],\n",
      "        ...,\n",
      "        [-0.0023, -0.0023, -0.0023,  ..., -0.0023, -0.0023, -0.0023],\n",
      "        [ 0.0040,  0.0040,  0.0040,  ...,  0.0040,  0.0040,  0.0040],\n",
      "        [-0.0033, -0.0033, -0.0033,  ..., -0.0033, -0.0033, -0.0033]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "print(loss.item())\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31430728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0346,  0.0075, -0.0243,  ..., -0.0262,  0.0271,  0.0190],\n",
      "        [ 0.0204, -0.0107,  0.0112,  ..., -0.0150,  0.0293, -0.0259],\n",
      "        [ 0.0314,  0.0012,  0.0093,  ...,  0.0076, -0.0251, -0.0213],\n",
      "        ...,\n",
      "        [ 0.0224,  0.0255, -0.0241,  ..., -0.0061, -0.0236, -0.0284],\n",
      "        [ 0.0113, -0.0223, -0.0012,  ...,  0.0321, -0.0262,  0.0207],\n",
      "        [ 0.0240, -0.0055, -0.0259,  ..., -0.0183, -0.0315, -0.0128]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36c46a",
   "metadata": {},
   "source": [
    "# Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "09c0b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.38777642299149084\n",
      "Training loss: 0.18653204612561\n",
      "Training loss: 0.13837089470581715\n",
      "Training loss: 0.11205514033199913\n",
      "Training loss: 0.09474295027194612\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "fd81a933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517a9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e37640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
